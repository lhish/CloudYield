//
//  AudioMonitorService.swift
//  StillMusicWhenBack
//
//  Èü≥È¢ëÁõëÊéßÊúçÂä° - ‰ΩøÁî® ScreenCaptureKit ÊçïËé∑Á≥ªÁªüÈü≥È¢ë
//

import Foundation
import ScreenCaptureKit
import AVFoundation
import CoreMedia

class AudioMonitorService: NSObject {
    // MARK: - Properties

    private var stream: SCStream?
    private var audioLevelDetector: AudioLevelDetector?
    private let audioQueue = DispatchQueue(label: "com.stillmusic.audio.processing", qos: .userInteractive)

    // ÂõûË∞ÉÔºöÂΩìÊ£ÄÊµãÂà∞Èü≥È¢ëÁ∫ßÂà´ÂèòÂåñÊó∂
    var onAudioLevelChanged: ((Bool) -> Void)?

    private var isMonitoring = false

    // MARK: - Initialization

    override init() {
        super.init()
        audioLevelDetector = AudioLevelDetector()

        // ËÆæÁΩÆÊ£ÄÊµãÂô®ÂõûË∞É
        audioLevelDetector?.onSignificantSoundDetected = { [weak self] hasSound in
            DispatchQueue.main.async {
                self?.onAudioLevelChanged?(hasSound)
            }
        }
    }

    // MARK: - Public Methods

    /// ÂºÄÂßãÁõëÊéßÁ≥ªÁªüÈü≥È¢ë
    func startMonitoring() async throws {
        guard !isMonitoring else {
            print("[AudioMonitor] Â∑≤ÁªèÂú®ÁõëÊéß‰∏≠")
            return
        }

        print("[AudioMonitor] üîß [DEBUG] Ê≠£Âú®ÂêØÂä®Èü≥È¢ëÁõëÊéß...")
        print("[AudioMonitor] üîß [DEBUG] Ê£ÄÊµãÂô®Â∑≤ËÆæÁΩÆ: \(audioLevelDetector != nil)")
        print("[AudioMonitor] üîß [DEBUG] ÂõûË∞ÉÂ∑≤ËÆæÁΩÆ: \(onAudioLevelChanged != nil)")

        do {
            // 1. Ëé∑ÂèñÂèØÊçïËé∑ÁöÑÂÜÖÂÆπ
            print("[AudioMonitor] üîß [DEBUG] Ê≠•È™§1: Ëé∑ÂèñÂèØÊçïËé∑ÂÜÖÂÆπ...")
            let content = try await SCShareableContent.excludingDesktopWindows(
                false,
                onScreenWindowsOnly: false
            )
            print("[AudioMonitor] üîß [DEBUG] ÊâæÂà∞ \(content.displays.count) ‰∏™ÊòæÁ§∫Âô®")
            print("[AudioMonitor] üîß [DEBUG] ÊâæÂà∞ \(content.windows.count) ‰∏™Á™óÂè£")

            // 2. ÂàõÂª∫ÈÖçÁΩÆ
            print("[AudioMonitor] üîß [DEBUG] Ê≠•È™§2: ÂàõÂª∫Èü≥È¢ëÈÖçÁΩÆ...")
            let config = SCStreamConfiguration()

            // Âè™ÊçïËé∑Èü≥È¢ëÔºå‰∏çÊçïËé∑ËßÜÈ¢ë
            config.capturesAudio = true
            config.excludesCurrentProcessAudio = true // ÊéíÈô§Êú¨Â∫îÁî®ÁöÑÈü≥È¢ë

            // Èü≥È¢ëÈÖçÁΩÆ
            config.sampleRate = 48000 // 48kHz ÈááÊ†∑Áéá
            config.channelCount = 2   // Á´ã‰ΩìÂ£∞
            print("[AudioMonitor] üîß [DEBUG] Èü≥È¢ëÈÖçÁΩÆ: ÈááÊ†∑Áéá=\(config.sampleRate), Â£∞ÈÅì=\(config.channelCount)")

            // 3. ÂàõÂª∫ÂÜÖÂÆπËøáÊª§Âô®ÔºàÊçïËé∑ÊâÄÊúâÈü≥È¢ëÔºâ
            print("[AudioMonitor] üîß [DEBUG] Ê≠•È™§3: ÂàõÂª∫ÂÜÖÂÆπËøáÊª§Âô®...")
            guard let display = content.displays.first else {
                print("[AudioMonitor] ‚ùå [DEBUG] Ê≤°ÊúâÊâæÂà∞ÂèØÁî®ÁöÑÊòæÁ§∫Âô®ÔºÅ")
                throw NSError(domain: "AudioMonitor", code: -1, userInfo: [NSLocalizedDescriptionKey: "Ê≤°ÊúâÊâæÂà∞ÂèØÁî®ÁöÑÊòæÁ§∫Âô®"])
            }
            print("[AudioMonitor] üîß [DEBUG] ‰ΩøÁî®ÊòæÁ§∫Âô®: \(display)")

            let filter = SCContentFilter(display: display, excludingWindows: [])
            print("[AudioMonitor] üîß [DEBUG] ËøáÊª§Âô®ÂàõÂª∫ÊàêÂäü")

            // 4. ÂàõÂª∫ÊµÅ
            print("[AudioMonitor] üîß [DEBUG] Ê≠•È™§4: ÂàõÂª∫ SCStream...")
            stream = SCStream(
                filter: filter,
                configuration: config,
                delegate: self
            )
            print("[AudioMonitor] üîß [DEBUG] SCStream ÂàõÂª∫ÊàêÂäü")

            // 5. Ê∑ªÂä†Èü≥È¢ëËæìÂá∫Â§ÑÁêÜ
            print("[AudioMonitor] üîß [DEBUG] Ê≠•È™§5: Ê∑ªÂä†Èü≥È¢ëËæìÂá∫Â§ÑÁêÜ...")
            try stream?.addStreamOutput(
                self,
                type: .audio,
                sampleHandlerQueue: audioQueue
            )
            print("[AudioMonitor] üîß [DEBUG] Èü≥È¢ëËæìÂá∫Â§ÑÁêÜÂ∑≤Ê∑ªÂä†")

            // 6. ÂêØÂä®ÊçïËé∑
            print("[AudioMonitor] üîß [DEBUG] Ê≠•È™§6: ÂêØÂä®ÊçïËé∑...")
            try await stream?.startCapture()

            isMonitoring = true
            print("[AudioMonitor] ‚úÖ Èü≥È¢ëÁõëÊéßÂ∑≤ÂêØÂä®ÊàêÂäüÔºÅ")

            // ÂêØÂä®Âü∫Á∫øÂ≠¶‰π†
            print("[AudioMonitor] üîß [DEBUG] ÂêØÂä®Âü∫Á∫øÂ≠¶‰π†...")
            audioLevelDetector?.startBaselineLearning()

        } catch {
            print("[AudioMonitor] ‚ùå ÂêØÂä®Â§±Ë¥•: \(error)")
            print("[AudioMonitor] ‚ùå [DEBUG] ÈîôËØØËØ¶ÊÉÖ: \(error.localizedDescription)")
            throw error
        }
    }

    /// ÂÅúÊ≠¢ÁõëÊéß
    func stopMonitoring() {
        guard isMonitoring else { return }

        print("[AudioMonitor] ÂÅúÊ≠¢Èü≥È¢ëÁõëÊéß...")

        Task {
            do {
                try await stream?.stopCapture()
                stream = nil
                isMonitoring = false
                print("[AudioMonitor] ‚úÖ Èü≥È¢ëÁõëÊéßÂ∑≤ÂÅúÊ≠¢")
            } catch {
                print("[AudioMonitor] ‚ùå ÂÅúÊ≠¢Â§±Ë¥•: \(error)")
            }
        }
    }

    // MARK: - Private Methods

    private func processAudioBuffer(_ sampleBuffer: CMSampleBuffer) {
        // ÊèêÂèñÈü≥È¢ëÊï∞ÊçÆ
        guard let audioBufferList = getAudioBufferList(from: sampleBuffer) else {
            return
        }

        // ‰º†ÈÄíÁªôÊ£ÄÊµãÂô®Â§ÑÁêÜ
        audioLevelDetector?.processAudioBuffer(audioBufferList)
    }

    private func getAudioBufferList(from sampleBuffer: CMSampleBuffer) -> AVAudioPCMBuffer? {
        guard let formatDescription = CMSampleBufferGetFormatDescription(sampleBuffer) else {
            return nil
        }

        guard let audioStreamBasicDescription = CMAudioFormatDescriptionGetStreamBasicDescription(formatDescription) else {
            return nil
        }

        let format = AVAudioFormat(streamDescription: audioStreamBasicDescription)
        guard let format = format else { return nil }

        let frameCount = CMSampleBufferGetNumSamples(sampleBuffer)
        guard let buffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: AVAudioFrameCount(frameCount)) else {
            return nil
        }

        buffer.frameLength = AVAudioFrameCount(frameCount)

        // ‰ªé CMSampleBuffer Â§çÂà∂Êï∞ÊçÆÂà∞ AVAudioPCMBuffer
        var audioBufferList = AudioBufferList()
        var blockBuffer: CMBlockBuffer?

        CMSampleBufferGetAudioBufferListWithRetainedBlockBuffer(
            sampleBuffer,
            bufferListSizeNeededOut: nil,
            bufferListOut: &audioBufferList,
            bufferListSize: MemoryLayout<AudioBufferList>.size,
            blockBufferAllocator: nil,
            blockBufferMemoryAllocator: nil,
            flags: 0,
            blockBufferOut: &blockBuffer
        )

        // Â§çÂà∂Êï∞ÊçÆ
        if let channelData = buffer.floatChannelData {
            for channel in 0..<Int(buffer.format.channelCount) {
                if let sourceData = audioBufferList.mBuffers.mData {
                    let source = sourceData.assumingMemoryBound(to: Float.self)
                    let destination = channelData[channel]
                    destination.update(from: source, count: Int(buffer.frameLength))
                }
            }
        }

        return buffer
    }
}

// MARK: - SCStreamDelegate
extension AudioMonitorService: SCStreamDelegate {
    func stream(_ stream: SCStream, didStopWithError error: Error) {
        print("[AudioMonitor] ‚ùå ÊµÅÂÅúÊ≠¢ÔºåÈîôËØØ: \(error)")
        isMonitoring = false
    }
}

// MARK: - SCStreamOutput
extension AudioMonitorService: SCStreamOutput {
    func stream(
        _ stream: SCStream,
        didOutputSampleBuffer sampleBuffer: CMSampleBuffer,
        of outputType: SCStreamOutputType
    ) {
        // Âè™Â§ÑÁêÜÈü≥È¢ëËæìÂá∫
        guard outputType == .audio else {
            print("[AudioMonitor] üîß [DEBUG] Êî∂Âà∞ÈùûÈü≥È¢ëËæìÂá∫ÔºåÁ±ªÂûã: \(outputType)")
            return
        }

        print("[AudioMonitor] üîß [DEBUG] Êî∂Âà∞Èü≥È¢ëÁºìÂÜ≤Âå∫")

        // Â§ÑÁêÜÈü≥È¢ëÁºìÂÜ≤Âå∫
        processAudioBuffer(sampleBuffer)
    }
}

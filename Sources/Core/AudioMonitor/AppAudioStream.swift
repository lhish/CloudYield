import Foundation
import ScreenCaptureKit
import AVFoundation
import CoreMedia
import Accelerate

/// å•ä¸ªåº”ç”¨çš„éŸ³é¢‘æµç›‘æ§
/// å‚è€ƒ OBS Studio çš„ mac-sck-audio-capture.m å®ç°
class AppAudioStream: NSObject {
    // MARK: - Properties

    let application: SCRunningApplication
    private var stream: SCStream?
    private var currentVolume: Float = 0.0
    private var isCapturing = false
    private var firstCapture = true  // ç”¨äºè°ƒè¯•è¾“å‡º

    private let audioQueue = DispatchQueue(
        label: "com.stillmusic.appstream.\(UUID().uuidString)",
        qos: .userInteractive
    )

    // èŠ‚æµï¼šé™åˆ¶å›è°ƒé¢‘ç‡
    private var lastCallbackTime: Date = .distantPast
    private let callbackInterval: TimeInterval = 1.0  // æ¯ç§’æœ€å¤š1æ¬¡å›è°ƒ

    // å›è°ƒ
    var onVolumeChanged: ((Float) -> Void)?

    // MARK: - Initialization

    init(application: SCRunningApplication) {
        self.application = application
        super.init()
    }

    // MARK: - Public Methods

    /// å¼€å§‹æ•è·éŸ³é¢‘
    func startCapture() async throws {
        guard !isCapturing else { return }

        logInfo("ğŸµ å¼€å§‹æ•è·åº”ç”¨éŸ³é¢‘: \(application.applicationName)", module: "AppAudioStream")

        // åˆ›å»ºé…ç½® - åªæ•è·éŸ³é¢‘
        let config = SCStreamConfiguration()

        // éŸ³é¢‘é…ç½®
        config.capturesAudio = true
        config.sampleRate = 48000
        config.channelCount = 2
        config.excludesCurrentProcessAudio = true

        // è§†é¢‘é…ç½®ï¼šå‚è€ƒ OBS çš„é…ç½®
        config.width = 16
        config.height = 16
        config.minimumFrameInterval = CMTime(value: 1, timescale: 1)  // 1 FPS
        config.pixelFormat = kCVPixelFormatType_32BGRA
        config.showsCursor = false
        config.queueDepth = 8  // OBS ä½¿ç”¨ 8

        // è·å–æ˜¾ç¤ºå™¨å’Œåº”ç”¨ï¼Œä½¿ç”¨ OBS çš„è¿‡æ»¤å™¨æ–¹å¼
        // display + includingApplicationsï¼ˆè€Œä¸æ˜¯ desktopIndependentWindowï¼‰
        let content = try await SCShareableContent.excludingDesktopWindows(false, onScreenWindowsOnly: false)

        guard let display = content.displays.first else {
            throw NSError(domain: "AppAudioStream", code: -1, userInfo: [NSLocalizedDescriptionKey: "æ‰¾ä¸åˆ°æ˜¾ç¤ºå™¨"])
        }

        // åˆ›å»ºè¿‡æ»¤å™¨ï¼šdisplay + includingï¼ˆOBS æ–¹å¼ï¼‰
        let filter = SCContentFilter(
            display: display,
            including: [application],
            exceptingWindows: []
        )

        logDebug("åˆ›å»ºè¿‡æ»¤å™¨: display+including(\(application.applicationName))", module: "AppAudioStream")

        // åˆ›å»ºæµ
        stream = SCStream(
            filter: filter,
            configuration: config,
            delegate: self
        )

        // æ·»åŠ éŸ³é¢‘è¾“å‡ºï¼ˆä½¿ç”¨ nil é˜Ÿåˆ—ï¼Œåƒ OBS ä¸€æ ·ï¼‰
        try stream?.addStreamOutput(
            self,
            type: .audio,
            sampleHandlerQueue: nil
        )

        // æ·»åŠ è§†é¢‘è¾“å‡ºï¼ˆåƒ OBS ä¸€æ ·ï¼Œç”¨äºæ¶ˆé™¤ SCK é”™è¯¯ï¼Œå¸§ä¼šåœ¨å›è°ƒä¸­è¢«ä¸¢å¼ƒï¼‰
        try stream?.addStreamOutput(
            self,
            type: .screen,
            sampleHandlerQueue: nil
        )

        // å¯åŠ¨æ•è·ï¼ˆæ”¯æŒå–æ¶ˆï¼‰
        try await withTaskCancellationHandler {
            try await stream?.startCapture()
        } onCancel: {
            // å¦‚æœä»»åŠ¡è¢«å–æ¶ˆï¼Œåœæ­¢æµ
            Task {
                try? await self.stream?.stopCapture()
            }
        }

        isCapturing = true
        logSuccess("âœ… åº”ç”¨éŸ³é¢‘æ•è·å·²å¯åŠ¨: \(application.applicationName)", module: "AppAudioStream")
    }

    /// åœæ­¢æ•è·
    func stopCapture() async {
        guard isCapturing else { return }

        logInfo("â¸ï¸ åœæ­¢æ•è·åº”ç”¨éŸ³é¢‘: \(application.applicationName)", module: "AppAudioStream")

        do {
            try await stream?.stopCapture()
        } catch {
            logError("åœæ­¢æ•è·å¤±è´¥: \(error)", module: "AppAudioStream")
        }

        stream = nil
        isCapturing = false
        currentVolume = 0.0
    }

    /// è·å–å½“å‰éŸ³é‡
    func getCurrentVolume() -> Float {
        return currentVolume
    }

    /// æ˜¯å¦æ­£åœ¨æ•è·
    func getIsCapturing() -> Bool {
        return isCapturing
    }

    // MARK: - Private Methods

    private func processAudioBuffer(_ sampleBuffer: CMSampleBuffer) {
        guard let samples = extractAudioSamples(from: sampleBuffer) else {
            return
        }

        // è®¡ç®— RMS
        let rms = calculateRMS(samples: samples)
        let dB = amplitudeToDecibels(rms)

        // æ›´æ–°éŸ³é‡
        currentVolume = dB

        // èŠ‚æµï¼šé™åˆ¶å›è°ƒé¢‘ç‡åˆ°æ¯ç§’1æ¬¡
        let now = Date()
        if now.timeIntervalSince(lastCallbackTime) >= callbackInterval {
            lastCallbackTime = now

            // è§¦å‘å›è°ƒ
            onVolumeChanged?(dB)

            // åªè®°å½•æœ‰æ„ä¹‰çš„éŸ³é‡ï¼ˆé¿å…æ—¥å¿—è¿‡å¤šï¼‰
            if dB > -40 {
                logDebug("[\(application.applicationName)] éŸ³é‡: \(String(format: "%.1f", dB)) dB", module: "AppAudioStream")
            }
        }
    }

    /// ä» CMSampleBuffer æå–éŸ³é¢‘é‡‡æ ·æ•°æ®
    /// å‚è€ƒ OBS çš„ screen_stream_audio_update å®ç°
    private func extractAudioSamples(from sampleBuffer: CMSampleBuffer) -> [Float]? {
        // é¦–å…ˆè·å–éœ€è¦çš„ AudioBufferList å¤§å°
        var bufferListSizeNeeded: Int = 0
        var status = CMSampleBufferGetAudioBufferListWithRetainedBlockBuffer(
            sampleBuffer,
            bufferListSizeNeededOut: &bufferListSizeNeeded,
            bufferListOut: nil,
            bufferListSize: 0,
            blockBufferAllocator: nil,
            blockBufferMemoryAllocator: nil,
            flags: 0,
            blockBufferOut: nil
        )

        guard status == noErr || status == kCMSampleBufferError_BufferHasNoSampleSizes else {
            logError("è·å– AudioBufferList å¤§å°å¤±è´¥: OSStatus=\(status)", module: "AppAudioStream")
            return nil
        }

        // åˆ†é…è¶³å¤Ÿçš„å†…å­˜
        let audioBufferListPointer = UnsafeMutablePointer<AudioBufferList>.allocate(capacity: 1)
        defer { audioBufferListPointer.deallocate() }

        var blockBuffer: CMBlockBuffer?
        status = CMSampleBufferGetAudioBufferListWithRetainedBlockBuffer(
            sampleBuffer,
            bufferListSizeNeededOut: nil,
            bufferListOut: audioBufferListPointer,
            bufferListSize: bufferListSizeNeeded,
            blockBufferAllocator: nil,
            blockBufferMemoryAllocator: nil,
            flags: kCMSampleBufferFlag_AudioBufferList_Assure16ByteAlignment,
            blockBufferOut: &blockBuffer
        )

        defer { blockBuffer = nil }

        guard status == noErr else {
            logError("æå–éŸ³é¢‘ç¼“å†²åŒºå¤±è´¥: OSStatus=\(status)", module: "AppAudioStream")
            return nil
        }

        // ä» AudioBufferList ä¸­æå– Float æ•°æ®
        let ablPointer = UnsafeMutableAudioBufferListPointer(audioBufferListPointer)

        guard let buffer = ablPointer.first,
              let data = buffer.mData else {
            return nil
        }

        let floatPtr = data.assumingMemoryBound(to: Float.self)
        let frameCount = Int(buffer.mDataByteSize) / MemoryLayout<Float>.size

        // è½¬æ¢ä¸º Swift æ•°ç»„
        let samples = Array(UnsafeBufferPointer(start: floatPtr, count: frameCount))

        // è¾“å‡ºå‰å‡ ä¸ªé‡‡æ ·å€¼ç”¨äºè°ƒè¯•ï¼ˆä»…åœ¨é¦–æ¬¡æ•è·æ—¶ï¼‰
        if firstCapture && !samples.isEmpty {
            let samplePreview = samples.prefix(5).map { String(format: "%.4f", $0) }.joined(separator: ", ")
            logDebug("[\(application.applicationName)] é¦–æ¬¡éŸ³é¢‘é‡‡æ ·: [\(samplePreview)...] (å…± \(frameCount) å¸§)", module: "AppAudioStream")
            firstCapture = false
        }

        return samples
    }

    /// è®¡ç®— RMSï¼ˆå‡æ–¹æ ¹ï¼‰
    private func calculateRMS(samples: [Float]) -> Float {
        guard !samples.isEmpty else { return 0.0 }

        var rms: Float = 0.0
        vDSP_rmsqv(samples, 1, &rms, vDSP_Length(samples.count))
        return rms
    }

    /// å°†æŒ¯å¹…è½¬æ¢ä¸ºåˆ†è´å€¼
    private func amplitudeToDecibels(_ amplitude: Float) -> Float {
        let safeAmplitude = max(amplitude, 1e-10) // é˜²æ­¢ log(0)
        return 20 * log10(safeAmplitude)
    }
}

// MARK: - SCStreamDelegate
extension AppAudioStream: SCStreamDelegate {
    func stream(_ stream: SCStream, didStopWithError error: Error) {
        logError("âŒ [\(application.applicationName)] æµåœæ­¢ï¼Œé”™è¯¯: \(error)", module: "AppAudioStream")
        isCapturing = false
        currentVolume = 0.0
    }
}

// MARK: - SCStreamOutput
extension AppAudioStream: SCStreamOutput {
    func stream(
        _ stream: SCStream,
        didOutputSampleBuffer sampleBuffer: CMSampleBuffer,
        of outputType: SCStreamOutputType
    ) {
        // åªå¤„ç†éŸ³é¢‘è¾“å‡º
        guard outputType == .audio else { return }
        processAudioBuffer(sampleBuffer)
    }
}

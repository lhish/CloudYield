import Foundation
import ScreenCaptureKit
import AVFoundation
import CoreMedia
import Accelerate

/// å•ä¸ªåº”ç”¨çš„éŸ³é¢‘æµç›‘æ§
/// å‚è€ƒ OBS Studio çš„ mac-sck-audio-capture.m å®ç°
class AppAudioStream: NSObject {
    // MARK: - Properties

    let application: SCRunningApplication
    private var stream: SCStream?
    private var currentVolume: Float = 0.0
    private var isCapturing = false
    private var firstCapture = true  // ç”¨äºè°ƒè¯•è¾“å‡º

    private let audioQueue = DispatchQueue(
        label: "com.stillmusic.appstream.\(UUID().uuidString)",
        qos: .userInteractive
    )

    // å›è°ƒ
    var onVolumeChanged: ((Float) -> Void)?

    // MARK: - Initialization

    init(application: SCRunningApplication) {
        self.application = application
        super.init()
    }

    // MARK: - Public Methods

    /// å¼€å§‹æ•è·éŸ³é¢‘
    func startCapture() async throws {
        guard !isCapturing else { return }

        logInfo("ğŸµ å¼€å§‹æ•è·åº”ç”¨éŸ³é¢‘: \(application.applicationName)", module: "AppAudioStream")

        // åˆ›å»ºé…ç½®
        let config = SCStreamConfiguration()
        config.capturesAudio = true
        config.sampleRate = 48000
        config.channelCount = 2
        config.excludesCurrentProcessAudio = true

        // æœ€å°è§†é¢‘é…ç½®ï¼ˆScreenCaptureKit è¦æ±‚å¿…é¡»é…ç½®è§†é¢‘ï¼‰
        config.width = 2
        config.height = 2
        config.minimumFrameInterval = CMTime(value: 1, timescale: 1)
        config.pixelFormat = kCVPixelFormatType_32BGRA
        config.showsCursor = false

        // åˆ›å»ºåº”ç”¨ç‰¹å®šçš„è¿‡æ»¤å™¨
        // æ ¹æ® ScreenCaptureKit æ–‡æ¡£ï¼ŒéŸ³é¢‘è¿‡æ»¤åªèƒ½åœ¨åº”ç”¨çº§åˆ«å·¥ä½œ
        // æˆ‘ä»¬éœ€è¦ä½¿ç”¨ display + excluding æ¥å®ç°åº”ç”¨çº§éŸ³é¢‘æ•è·
        guard let display = try? await SCShareableContent.excludingDesktopWindows(false, onScreenWindowsOnly: false).displays.first else {
            throw NSError(domain: "AppAudioStream", code: -1, userInfo: [NSLocalizedDescriptionKey: "æ‰¾ä¸åˆ°æ˜¾ç¤ºå™¨"])
        }

        // æ’é™¤æ‰€æœ‰åº”ç”¨ï¼Œåªä¿ç•™æˆ‘ä»¬è¦ç›‘æ§çš„è¿™ä¸€ä¸ªåº”ç”¨
        let allApps = try await SCShareableContent.excludingDesktopWindows(false, onScreenWindowsOnly: false).applications
        let appsToExclude = allApps.filter { $0.bundleIdentifier != application.bundleIdentifier }

        let filter = SCContentFilter(
            display: display,
            excludingApplications: appsToExclude,
            exceptingWindows: []
        )

        logDebug("åˆ›å»ºè¿‡æ»¤å™¨: desktopIndependentWindow(\(application.applicationName))", module: "AppAudioStream")

        // åˆ›å»ºæµ
        stream = SCStream(
            filter: filter,
            configuration: config,
            delegate: self
        )

        // æ·»åŠ éŸ³é¢‘è¾“å‡º
        try stream?.addStreamOutput(
            self,
            type: .audio,
            sampleHandlerQueue: audioQueue
        )

        // å¯åŠ¨æ•è·
        try await stream?.startCapture()

        isCapturing = true
        logSuccess("âœ… åº”ç”¨éŸ³é¢‘æ•è·å·²å¯åŠ¨: \(application.applicationName)", module: "AppAudioStream")
    }

    /// åœæ­¢æ•è·
    func stopCapture() async {
        guard isCapturing else { return }

        logInfo("â¸ï¸ åœæ­¢æ•è·åº”ç”¨éŸ³é¢‘: \(application.applicationName)", module: "AppAudioStream")

        do {
            try await stream?.stopCapture()
        } catch {
            logError("åœæ­¢æ•è·å¤±è´¥: \(error)", module: "AppAudioStream")
        }

        stream = nil
        isCapturing = false
        currentVolume = 0.0
    }

    /// è·å–å½“å‰éŸ³é‡
    func getCurrentVolume() -> Float {
        return currentVolume
    }

    /// æ˜¯å¦æ­£åœ¨æ•è·
    func getIsCapturing() -> Bool {
        return isCapturing
    }

    // MARK: - Private Methods

    private func processAudioBuffer(_ sampleBuffer: CMSampleBuffer) {
        guard let samples = extractAudioSamples(from: sampleBuffer) else {
            return
        }

        // è®¡ç®— RMS
        let rms = calculateRMS(samples: samples)
        let dB = amplitudeToDecibels(rms)

        // æ›´æ–°éŸ³é‡
        currentVolume = dB

        // è§¦å‘å›è°ƒ
        onVolumeChanged?(dB)

        // åªè®°å½•æœ‰æ„ä¹‰çš„éŸ³é‡ï¼ˆé¿å…æ—¥å¿—è¿‡å¤šï¼‰
        if dB > -40 {
            logDebug("[\(application.applicationName)] éŸ³é‡: \(String(format: "%.1f", dB)) dB", module: "AppAudioStream")
        }
    }

    /// ä» CMSampleBuffer æå–éŸ³é¢‘é‡‡æ ·æ•°æ®
    /// å‚è€ƒ OBS çš„ screen_stream_audio_update å®ç°
    private func extractAudioSamples(from sampleBuffer: CMSampleBuffer) -> [Float]? {
        // é¦–å…ˆè·å–éœ€è¦çš„ AudioBufferList å¤§å°
        var bufferListSizeNeeded: Int = 0
        var status = CMSampleBufferGetAudioBufferListWithRetainedBlockBuffer(
            sampleBuffer,
            bufferListSizeNeededOut: &bufferListSizeNeeded,
            bufferListOut: nil,
            bufferListSize: 0,
            blockBufferAllocator: nil,
            blockBufferMemoryAllocator: nil,
            flags: 0,
            blockBufferOut: nil
        )

        guard status == noErr || status == kCMSampleBufferError_BufferHasNoSampleSizes else {
            logError("è·å– AudioBufferList å¤§å°å¤±è´¥: OSStatus=\(status)", module: "AppAudioStream")
            return nil
        }

        // åˆ†é…è¶³å¤Ÿçš„å†…å­˜
        let audioBufferListPointer = UnsafeMutablePointer<AudioBufferList>.allocate(capacity: 1)
        defer { audioBufferListPointer.deallocate() }

        var blockBuffer: CMBlockBuffer?
        status = CMSampleBufferGetAudioBufferListWithRetainedBlockBuffer(
            sampleBuffer,
            bufferListSizeNeededOut: nil,
            bufferListOut: audioBufferListPointer,
            bufferListSize: bufferListSizeNeeded,
            blockBufferAllocator: nil,
            blockBufferMemoryAllocator: nil,
            flags: kCMSampleBufferFlag_AudioBufferList_Assure16ByteAlignment,
            blockBufferOut: &blockBuffer
        )

        defer { blockBuffer = nil }

        guard status == noErr else {
            logError("æå–éŸ³é¢‘ç¼“å†²åŒºå¤±è´¥: OSStatus=\(status)", module: "AppAudioStream")
            return nil
        }

        // ä» AudioBufferList ä¸­æå– Float æ•°æ®
        let ablPointer = UnsafeMutableAudioBufferListPointer(audioBufferListPointer)

        guard let buffer = ablPointer.first,
              let data = buffer.mData else {
            return nil
        }

        let floatPtr = data.assumingMemoryBound(to: Float.self)
        let frameCount = Int(buffer.mDataByteSize) / MemoryLayout<Float>.size

        // è½¬æ¢ä¸º Swift æ•°ç»„
        let samples = Array(UnsafeBufferPointer(start: floatPtr, count: frameCount))

        // è¾“å‡ºå‰å‡ ä¸ªé‡‡æ ·å€¼ç”¨äºè°ƒè¯•ï¼ˆä»…åœ¨é¦–æ¬¡æ•è·æ—¶ï¼‰
        if firstCapture && !samples.isEmpty {
            let samplePreview = samples.prefix(5).map { String(format: "%.4f", $0) }.joined(separator: ", ")
            logDebug("[\(application.applicationName)] é¦–æ¬¡éŸ³é¢‘é‡‡æ ·: [\(samplePreview)...] (å…± \(frameCount) å¸§)", module: "AppAudioStream")
            firstCapture = false
        }

        return samples
    }

    /// è®¡ç®— RMSï¼ˆå‡æ–¹æ ¹ï¼‰
    private func calculateRMS(samples: [Float]) -> Float {
        guard !samples.isEmpty else { return 0.0 }

        var rms: Float = 0.0
        vDSP_rmsqv(samples, 1, &rms, vDSP_Length(samples.count))
        return rms
    }

    /// å°†æŒ¯å¹…è½¬æ¢ä¸ºåˆ†è´å€¼
    private func amplitudeToDecibels(_ amplitude: Float) -> Float {
        let safeAmplitude = max(amplitude, 1e-10) // é˜²æ­¢ log(0)
        return 20 * log10(safeAmplitude)
    }
}

// MARK: - SCStreamDelegate
extension AppAudioStream: SCStreamDelegate {
    func stream(_ stream: SCStream, didStopWithError error: Error) {
        logError("âŒ [\(application.applicationName)] æµåœæ­¢ï¼Œé”™è¯¯: \(error)", module: "AppAudioStream")
        isCapturing = false
        currentVolume = 0.0
    }
}

// MARK: - SCStreamOutput
extension AppAudioStream: SCStreamOutput {
    func stream(
        _ stream: SCStream,
        didOutputSampleBuffer sampleBuffer: CMSampleBuffer,
        of outputType: SCStreamOutputType
    ) {
        // åªå¤„ç†éŸ³é¢‘è¾“å‡º
        guard outputType == .audio else { return }
        processAudioBuffer(sampleBuffer)
    }
}

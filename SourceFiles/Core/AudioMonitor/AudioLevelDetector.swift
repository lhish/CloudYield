//
//  AudioLevelDetector.swift
//  StillMusicWhenBack
//
//  éŸ³é¢‘çº§åˆ«æ£€æµ‹å™¨ - è®¡ç®— RMSã€Peak å€¼å¹¶æ™ºèƒ½åˆ¤æ–­æ˜¯å¦æœ‰æœ‰æ•ˆå£°éŸ³
//

import Foundation
import AVFoundation
import Accelerate

class AudioLevelDetector {
    // MARK: - Properties

    // åŸºçº¿å™ªéŸ³çº§åˆ«ï¼ˆdBï¼‰
    private var baselineNoiseLevel: Float = -60.0
    private var isLearningBaseline = false
    private var baselineSamples: [Float] = []
    private let baselineDuration: TimeInterval = 10.0 // å­¦ä¹ 10ç§’åŸºçº¿

    // æ£€æµ‹é˜ˆå€¼ï¼ˆç›¸å¯¹äºåŸºçº¿çš„åç§»ï¼Œå•ä½ï¼šdBï¼‰
    private let thresholdOffset: Float = 15.0

    // æ»‘åŠ¨çª—å£ï¼Œç”¨äºå¹³æ»‘éŸ³é‡æ³¢åŠ¨
    private var recentLevels: [Float] = []
    private let windowSize = 5

    // å›è°ƒ
    var onSignificantSoundDetected: ((Bool) -> Void)?

    private var lastSignificantSound: Bool = false

    // MARK: - Public Methods

    /// å¼€å§‹åŸºçº¿å­¦ä¹ 
    func startBaselineLearning() {
        print("[AudioDetector] å¼€å§‹å­¦ä¹ ç¯å¢ƒå™ªéŸ³åŸºçº¿ï¼ˆ10ç§’ï¼‰...")
        isLearningBaseline = true
        baselineSamples = []

        // 10ç§’åç»“æŸåŸºçº¿å­¦ä¹ 
        DispatchQueue.main.asyncAfter(deadline: .now() + baselineDuration) { [weak self] in
            self?.finishBaselineLearning()
        }
    }

    /// å¤„ç†éŸ³é¢‘ç¼“å†²åŒº
    func processAudioBuffer(_ buffer: AVAudioPCMBuffer) {
        guard let channelData = buffer.floatChannelData else { return }

        let frameLength = Int(buffer.frameLength)
        let channelCount = Int(buffer.format.channelCount)

        // è®¡ç®— RMSï¼ˆå‡æ–¹æ ¹ï¼‰
        var rms: Float = 0.0

        for channel in 0..<channelCount {
            let samples = channelData[channel]
            var channelRMS: Float = 0.0

            // ä½¿ç”¨ vDSP åŠ é€Ÿè®¡ç®—
            vDSP_rmsqv(samples, 1, &channelRMS, vDSP_Length(frameLength))

            rms += channelRMS
        }

        // å–å¹³å‡
        rms /= Float(channelCount)

        // è½¬æ¢ä¸º dB
        let dB = amplitudeToDecibels(rms)

        // å¦‚æœæ­£åœ¨å­¦ä¹ åŸºçº¿
        if isLearningBaseline {
            baselineSamples.append(dB)
            return
        }

        // æ·»åŠ åˆ°æ»‘åŠ¨çª—å£
        recentLevels.append(dB)
        if recentLevels.count > windowSize {
            recentLevels.removeFirst()
        }

        // è®¡ç®—å¹³æ»‘åçš„éŸ³é‡
        let smoothedLevel = recentLevels.reduce(0, +) / Float(recentLevels.count)

        // åˆ¤æ–­æ˜¯å¦æœ‰æ˜¾è‘—å£°éŸ³
        let hasSignificantSound = smoothedLevel > (baselineNoiseLevel + thresholdOffset)

        // åªåœ¨çŠ¶æ€å˜åŒ–æ—¶è§¦å‘å›è°ƒ
        if hasSignificantSound != lastSignificantSound {
            lastSignificantSound = hasSignificantSound

            if hasSignificantSound {
                print("[AudioDetector] ğŸ”Š æ£€æµ‹åˆ°æ˜¾è‘—å£°éŸ³: \(String(format: "%.1f", smoothedLevel)) dB (åŸºçº¿: \(String(format: "%.1f", baselineNoiseLevel)) dB)")
            } else {
                print("[AudioDetector] ğŸ”‡ å£°éŸ³æ¶ˆå¤±")
            }

            onSignificantSoundDetected?(hasSignificantSound)
        }
    }

    // MARK: - Private Methods

    private func finishBaselineLearning() {
        isLearningBaseline = false

        guard !baselineSamples.isEmpty else {
            print("[AudioDetector] âš ï¸  åŸºçº¿å­¦ä¹ å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            return
        }

        // è®¡ç®—åŸºçº¿ï¼ˆå–ä¸­ä½æ•°ï¼Œé¿å…å¼‚å¸¸å€¼å½±å“ï¼‰
        let sortedSamples = baselineSamples.sorted()
        let medianIndex = sortedSamples.count / 2
        baselineNoiseLevel = sortedSamples[medianIndex]

        print("[AudioDetector] âœ… åŸºçº¿å­¦ä¹ å®Œæˆ: \(String(format: "%.1f", baselineNoiseLevel)) dB")
        print("[AudioDetector] æ£€æµ‹é˜ˆå€¼: \(String(format: "%.1f", baselineNoiseLevel + thresholdOffset)) dB")

        baselineSamples = []
    }

    /// å°†æŒ¯å¹…è½¬æ¢ä¸ºåˆ†è´
    private func amplitudeToDecibels(_ amplitude: Float) -> Float {
        // é¿å… log(0)
        let safeAmplitude = max(amplitude, 1e-10)

        // è½¬æ¢ä¸º dB (å‚è€ƒå€¼: 1.0)
        return 20 * log10(safeAmplitude)
    }
}
